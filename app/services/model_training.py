# app/services/model_training.py
"""
–ú–æ–¥—É–ª—å –æ–±—É—á–µ–Ω–∏—è –∞–Ω—Å–∞–º–±–ª–µ–≤–æ–π –º–æ–¥–µ–ª–∏

–ú–æ–¥—É–ª—å —Ä–µ–∞–ª–∏–∑—É–µ—Ç –æ–±—É—á–µ–Ω–∏–µ –∞–Ω—Å–∞–º–±–ª—è –∏–∑ —Ç—Ä—ë—Ö –º–æ–¥–µ–ª–µ–π:
- RandomForest
- XGBoost
- CatBoost

–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è VotingClassifier —Å –º—è–≥–∫–∏–º –≥–æ–ª–æ—Å–æ–≤–∞–Ω–∏–µ–º (soft voting),
—á—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç —É—á–∏—Ç—ã–≤–∞—Ç—å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏.

–û—Å–Ω–æ–≤–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏:
- train_ensemble_model: –æ–±—É—á–µ–Ω–∏–µ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∞–Ω—Å–∞–º–±–ª—è

–ê–≤—Ç–æ—Ä: [–ö–æ—á–Ω–µ–≤–∞ –ê—Ä–∏–Ω–∞]
–ì–æ–¥: 2025
"""

from sklearn.ensemble import VotingClassifier
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from catboost import CatBoostClassifier
import joblib
import logging

# –ò–º–ø–æ—Ä—Ç –ø—É—Ç–µ–π –∏–∑ —Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
from shared.config import (
    ENSEMBLE_MODEL_PATH,
    FEATURE_NAMES_PATH,
    BACKGROUND_DATA_PATH
)


logger = logging.getLogger(__name__)


def train_ensemble_model(X, y):
    """
    –û–±—É—á–∞–µ—Ç –∞–Ω—Å–∞–º–±–ª–µ–≤—É—é –º–æ–¥–µ–ª—å –º–µ—Ç–æ–¥–æ–º –≥–æ–ª–æ—Å–æ–≤–∞–Ω–∏—è
        (VotingClassifier).

    –ê–Ω—Å–∞–º–±–ª—å —Å–æ—Å—Ç–æ–∏—Ç –∏–∑ —Ç—Ä—ë—Ö –º–æ–¥–µ–ª–µ–π:
        - RandomForestClassifier
        - XGBClassifier
        - CatBoostClassifier

    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è **–º—è–≥–∫–æ–µ –≥–æ–ª–æ—Å–æ–≤–∞–Ω–∏–µ (soft voting)** ‚Äî
    —É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π, —á—Ç–æ –¥–∞—ë—Ç –±–æ–ª–µ–µ —Å—Ç–∞–±–∏–ª—å–Ω—ã–µ –∏
    —Ç–æ—á–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å –∂—ë—Å—Ç–∫–∏–º –≥–æ–ª–æ—Å–æ–≤–∞–Ω–∏–µ–º.

    –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –≤–º–µ—Å—Ç–µ —Å:
        - feature_names.pkl ‚Äî —Å–ø–∏—Å–æ–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–¥–ª—è —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏
            –ø—Ä–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–∏)
        - background_data.pkl ‚Äî –ø–æ–¥–≤—ã–±–æ—Ä–∫–∞ –¥–ª—è SHAP-–æ–±—ä—è—Å–Ω–µ–Ω–∏–π

    Args:
        X (pd.DataFrame –∏–ª–∏ np.ndarray): –ú–∞—Ç—Ä–∏—Ü–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (—Ñ–∏—á–µ–π)
        y (pd.Series –∏–ª–∏ np.ndarray): –í–µ–∫—Ç–æ—Ä —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
            (0 ‚Äî repaid, 1 ‚Äî default)

    Returns:
        dict: –†–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—É—á–µ–Ω–∏—è —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –º–æ–¥–µ–ª–∏ –∏ –µ—ë —Ç–æ—á–Ω–æ—Å—Ç–∏:
            {
                "model": "Ensemble (RF + XGBoost + CatBoost)",
                "accuracy": 0.934
            }

    Raises:
        ValueError: –ï—Å–ª–∏ X –∏–ª–∏ y –ø—É—Å—Ç—ã
        ValueError: –ï—Å–ª–∏ —Ä–∞–∑–º–µ—Ä—ã X –∏ y –Ω–µ —Å–æ–≤–ø–∞–¥–∞—é—Ç
        Exception: –ï—Å–ª–∏ –≤–æ–∑–Ω–∏–∫–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –æ–¥–Ω–æ–π –∏–∑ –º–æ–¥–µ–ª–µ–π

    –ü—Ä–∏–º–µ—á–∞–Ω–∏—è:
        - –í—Å–µ –º–æ–¥–µ–ª–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—Ç—Å—è —Å random_state=42 –¥–ª—è
            –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏
        - CatBoost —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ silent-—Ä–µ–∂–∏–º–µ (–±–µ–∑ –ª–æ–≥–æ–≤)
        - XGBoost: –æ—Ç–∫–ª—é—á—ë–Ω use_label_encoder, —É–∫–∞–∑–∞–Ω–∞ eval_metric
        - VotingClassifier: voting='soft' ‚Äî —É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π

    –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:
        >>> X, y = preprocess_data(df)
        >>> result = train_ensemble_model(X, y)
        >>> print(f"–¢–æ—á–Ω–æ—Å—Ç—å: {result['accuracy']:.3f}")
    """
    # –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    if X.empty or len(X) == 0:
        raise ValueError("–ú–∞—Ç—Ä–∏—Ü–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ X –ø—É—Å—Ç–∞")
    if len(X) != len(y):
        raise ValueError(
            f"–†–∞–∑–º–µ—Ä—ã X ({len(X)}) –∏ y ({len(y)}) –Ω–µ —Å–æ–≤–ø–∞–¥–∞—é—Ç"
        )

    # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∞–Ω—Å–∞–º–±–ª–µ–≤–æ–π –º–æ–¥–µ–ª–∏
    model = VotingClassifier(
        estimators=[
            # 1. –°–ª—É—á–∞–π–Ω—ã–π –ª–µ—Å ‚Äî —É—Å—Ç–æ–π—á–∏–≤ –∫ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—é
            (
                'rf',
                RandomForestClassifier(
                    n_estimators=50,           # –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–µ—Ä–µ–≤—å–µ–≤
                    random_state=42,           # –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç—å
                    n_jobs=-1                  # –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
                )
            ),
            # 2. XGBoost ‚Äî –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π –±—É—Å—Ç–∏–Ω–≥, –≤—ã—Å–æ–∫–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å
            (
                'xgb',
                XGBClassifier(
                    use_label_encoder=False,   # –æ—Ç–∫–ª—é—á–∞–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ
                    eval_metric='logloss',     # –º–µ—Ç—Ä–∏–∫–∞ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
                    random_state=42,           # –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç—å
                    n_jobs=-1                  # —É—Å–∫–æ—Ä–µ–Ω–∏–µ
                )
            ),
            # 3. CatBoost ‚Äî –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            (
                'cb',
                CatBoostClassifier(
                    silent=True,               # –æ—Ç–∫–ª—é—á–∞–µ–º –≤—ã–≤–æ–¥ –≤ –∫–æ–Ω—Å–æ–ª—å
                    random_state=42,           # –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç—å
                    #verbose=0                  # –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞ silent
                )
            )
        ],
        voting='soft'  # —É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π (–ª—É—á—à–µ –¥–ª—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç–∏)
    )

    # –û–±—É—á–µ–Ω–∏–µ –∞–Ω—Å–∞–º–±–ª—è –Ω–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö
    logger.info("üöÄ –ù–∞—á–∞–ª–æ –æ–±—É—á–µ–Ω–∏—è –∞–Ω—Å–∞–º–±–ª–µ–≤–æ–π –º–æ–¥–µ–ª–∏...")
    model.fit(X, y)
    logger.info("‚úÖ –ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞")

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
    logger.info(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏: {ENSEMBLE_MODEL_PATH}")
    joblib.dump(model, ENSEMBLE_MODEL_PATH)

    logger.info(
        f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –Ω–∞–∑–≤–∞–Ω–∏–π –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {FEATURE_NAMES_PATH}"
    )
    joblib.dump(X.columns.tolist(), FEATURE_NAMES_PATH)

    logger.info(
        f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ background_data: {BACKGROUND_DATA_PATH}"
    )
    background_data = X.sample(min(100, len(X)), random_state=42)
    joblib.dump(background_data, BACKGROUND_DATA_PATH)

    # –û—Ü–µ–Ω–∫–∞ —Ç–æ—á–Ω–æ—Å—Ç–∏ –Ω–∞ –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–µ
    accuracy = model.score(X, y)
    logger.info(
        f"üìä –¢–æ—á–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏ –Ω–∞ –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–µ: {accuracy:.3f}"
    )

    return {
        "model": "Ensemble (RF + XGBoost + CatBoost)",
        "accuracy": accuracy
    }
